{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ViT tiny\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ViTForImageClassification(\n",
      "  (vit): ViTModel(\n",
      "    (embeddings): ViTEmbeddings(\n",
      "      (patch_embeddings): ViTPatchEmbeddings(\n",
      "        (projection): Conv2d(3, 192, kernel_size=(16, 16), stride=(16, 16))\n",
      "      )\n",
      "      (dropout): Dropout(p=0.0, inplace=False)\n",
      "    )\n",
      "    (encoder): ViTEncoder(\n",
      "      (layer): ModuleList(\n",
      "        (0-11): 12 x ViTLayer(\n",
      "          (attention): ViTSdpaAttention(\n",
      "            (attention): ViTSdpaSelfAttention(\n",
      "              (query): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (key): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (value): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "            (output): ViTSelfOutput(\n",
      "              (dense): Linear(in_features=192, out_features=192, bias=True)\n",
      "              (dropout): Dropout(p=0.0, inplace=False)\n",
      "            )\n",
      "          )\n",
      "          (intermediate): ViTIntermediate(\n",
      "            (dense): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (intermediate_act_fn): GELUActivation()\n",
      "          )\n",
      "          (output): ViTOutput(\n",
      "            (dense): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (dropout): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (layernorm_before): LayerNorm((192,), eps=1e-12, elementwise_affine=True)\n",
      "          (layernorm_after): LayerNorm((192,), eps=1e-12, elementwise_affine=True)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (layernorm): LayerNorm((192,), eps=1e-12, elementwise_affine=True)\n",
      "  )\n",
      "  (classifier): Linear(in_features=192, out_features=1000, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoImageProcessor, AutoConfig, AutoModelForImageClassification\n",
    "\n",
    "# Load the processor (no need to change this as it only handles preprocessing)\n",
    "processor = AutoImageProcessor.from_pretrained(\"WinKawaks/vit-tiny-patch16-224\")\n",
    "\n",
    "# Load the configuration\n",
    "config = AutoConfig.from_pretrained(\"WinKawaks/vit-tiny-patch16-224\")\n",
    "config.image_size = 28\n",
    "\n",
    "# Initialize the model with the configuration (without pretrained weights)\n",
    "model = AutoModelForImageClassification.from_config(config)\n",
    "\n",
    "# Print the model architecture to verify\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Preparing data..\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "best_acc = 0  # best test accuracy\n",
    "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
    "\n",
    "# Data\n",
    "print('==> Preparing data..')\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(28, padding=4),\n",
    "    transforms.Grayscale(3),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.Grayscale(3),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
    "])\n",
    "\n",
    "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transform_train)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True, num_workers=2)\n",
    "\n",
    "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transform_test)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=100, shuffle=False, num_workers=2)\n",
    "\n",
    "classes = ('plane', 'car', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==> Building model..\n"
     ]
    }
   ],
   "source": [
    "print('==> Building model..')\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "\n",
    "if device == 'cuda':\n",
    "    model = torch.nn.DataParallel(model)\n",
    "    cudnn.benchmark = True\n",
    "\n",
    "\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#criterion = nn.NLLLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=1e-3, momentum=0.9, weight_decay=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training\n",
    "def train(epochs):\n",
    "    model.train()\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for batch_idx, (data, target) in enumerate(trainloader):\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            logits = output.logits\n",
    "            loss = criterion(logits, target)\n",
    "            #loss = nn.NLLLoss(output,target)\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "            if batch_idx % 100 == 0:\n",
    "                done = batch_idx * len(data)\n",
    "                percentage = 100. * batch_idx / len(trainloader)\n",
    "                print(f'Train Epoch: {epoch} [{done:5}/{len(trainloader.dataset)} ({percentage:3.0f}%)]  Loss: {loss.item():.6f}')\n",
    "\n",
    "        test(trainloader)\n",
    "        test(testloader)\n",
    "\n",
    "\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            logits = output.logits\n",
    "            test_loss += criterion(logits, target).item() # sum up batch loss\n",
    "            #test_loss += nn.NLLLoss(output, target).item()\n",
    "            pred = logits.max(1, keepdim=True)[1] # get the index of the max log-probability\n",
    "            correct += pred.eq(target.data.view_as(pred)).sum().item()\n",
    "\n",
    "        test_loss /= len(loader.dataset)\n",
    "        accuracy = 100. * correct / len(loader.dataset)\n",
    "        print(f'Test set: Average loss: {test_loss:.4f}, Accuracy: {correct}/{len(loader.dataset)} ({accuracy:.2f}%)')\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 0 [    0/60000 (  0%)]  Loss: 6.917477\n",
      "Train Epoch: 0 [12800/60000 ( 21%)]  Loss: 2.320316\n",
      "Train Epoch: 0 [25600/60000 ( 43%)]  Loss: 2.193535\n",
      "Train Epoch: 0 [38400/60000 ( 64%)]  Loss: 2.139564\n",
      "Train Epoch: 0 [51200/60000 ( 85%)]  Loss: 1.987333\n",
      "Test set: Average loss: 0.0145, Accuracy: 20901/60000 (34.84%)\n",
      "Test set: Average loss: 0.0169, Accuracy: 4713/10000 (47.13%)\n",
      "Train Epoch: 1 [    0/60000 (  0%)]  Loss: 1.844213\n",
      "Train Epoch: 1 [12800/60000 ( 21%)]  Loss: 1.647928\n",
      "Train Epoch: 1 [25600/60000 ( 43%)]  Loss: 1.729648\n",
      "Train Epoch: 1 [38400/60000 ( 64%)]  Loss: 1.414802\n",
      "Train Epoch: 1 [51200/60000 ( 85%)]  Loss: 1.396925\n",
      "Test set: Average loss: 0.0108, Accuracy: 30851/60000 (51.42%)\n",
      "Test set: Average loss: 0.0124, Accuracy: 5752/10000 (57.52%)\n",
      "Train Epoch: 2 [    0/60000 (  0%)]  Loss: 1.386515\n",
      "Train Epoch: 2 [12800/60000 ( 21%)]  Loss: 1.232014\n",
      "Train Epoch: 2 [25600/60000 ( 43%)]  Loss: 1.371408\n",
      "Train Epoch: 2 [38400/60000 ( 64%)]  Loss: 1.379066\n",
      "Train Epoch: 2 [51200/60000 ( 85%)]  Loss: 1.248289\n",
      "Test set: Average loss: 0.0097, Accuracy: 34339/60000 (57.23%)\n",
      "Test set: Average loss: 0.0109, Accuracy: 6294/10000 (62.94%)\n",
      "Train Epoch: 3 [    0/60000 (  0%)]  Loss: 1.276243\n",
      "Train Epoch: 3 [12800/60000 ( 21%)]  Loss: 1.177383\n",
      "Train Epoch: 3 [25600/60000 ( 43%)]  Loss: 1.184660\n",
      "Train Epoch: 3 [38400/60000 ( 64%)]  Loss: 1.050678\n",
      "Train Epoch: 3 [51200/60000 ( 85%)]  Loss: 1.250864\n",
      "Test set: Average loss: 0.0090, Accuracy: 36288/60000 (60.48%)\n",
      "Test set: Average loss: 0.0106, Accuracy: 6458/10000 (64.58%)\n",
      "Train Epoch: 4 [    0/60000 (  0%)]  Loss: 1.330896\n",
      "Train Epoch: 4 [12800/60000 ( 21%)]  Loss: 1.042109\n",
      "Train Epoch: 4 [25600/60000 ( 43%)]  Loss: 1.053512\n",
      "Train Epoch: 4 [38400/60000 ( 64%)]  Loss: 1.118216\n",
      "Train Epoch: 4 [51200/60000 ( 85%)]  Loss: 1.045777\n",
      "Test set: Average loss: 0.0087, Accuracy: 36833/60000 (61.39%)\n",
      "Test set: Average loss: 0.0106, Accuracy: 6403/10000 (64.03%)\n",
      "Train Epoch: 5 [    0/60000 (  0%)]  Loss: 1.145460\n",
      "Train Epoch: 5 [12800/60000 ( 21%)]  Loss: 1.291496\n",
      "Train Epoch: 5 [25600/60000 ( 43%)]  Loss: 1.104189\n",
      "Train Epoch: 5 [38400/60000 ( 64%)]  Loss: 1.099827\n",
      "Train Epoch: 5 [51200/60000 ( 85%)]  Loss: 1.124294\n",
      "Test set: Average loss: 0.0086, Accuracy: 37059/60000 (61.77%)\n",
      "Test set: Average loss: 0.0108, Accuracy: 6186/10000 (61.86%)\n",
      "Train Epoch: 6 [    0/60000 (  0%)]  Loss: 1.178957\n",
      "Train Epoch: 6 [12800/60000 ( 21%)]  Loss: 0.976129\n",
      "Train Epoch: 6 [25600/60000 ( 43%)]  Loss: 1.112028\n",
      "Train Epoch: 6 [38400/60000 ( 64%)]  Loss: 1.060894\n",
      "Train Epoch: 6 [51200/60000 ( 85%)]  Loss: 1.008791\n",
      "Test set: Average loss: 0.0082, Accuracy: 38175/60000 (63.62%)\n",
      "Test set: Average loss: 0.0093, Accuracy: 6666/10000 (66.66%)\n",
      "Train Epoch: 7 [    0/60000 (  0%)]  Loss: 0.861027\n",
      "Train Epoch: 7 [12800/60000 ( 21%)]  Loss: 1.155616\n",
      "Train Epoch: 7 [25600/60000 ( 43%)]  Loss: 1.101290\n",
      "Train Epoch: 7 [38400/60000 ( 64%)]  Loss: 0.844466\n",
      "Train Epoch: 7 [51200/60000 ( 85%)]  Loss: 0.985592\n",
      "Test set: Average loss: 0.0082, Accuracy: 38090/60000 (63.48%)\n",
      "Test set: Average loss: 0.0095, Accuracy: 6431/10000 (64.31%)\n",
      "Train Epoch: 8 [    0/60000 (  0%)]  Loss: 1.012909\n",
      "Train Epoch: 8 [12800/60000 ( 21%)]  Loss: 0.876443\n",
      "Train Epoch: 8 [25600/60000 ( 43%)]  Loss: 1.043564\n",
      "Train Epoch: 8 [38400/60000 ( 64%)]  Loss: 0.967112\n",
      "Train Epoch: 8 [51200/60000 ( 85%)]  Loss: 1.026376\n",
      "Test set: Average loss: 0.0080, Accuracy: 38617/60000 (64.36%)\n",
      "Test set: Average loss: 0.0092, Accuracy: 6736/10000 (67.36%)\n",
      "Train Epoch: 9 [    0/60000 (  0%)]  Loss: 1.106067\n",
      "Train Epoch: 9 [12800/60000 ( 21%)]  Loss: 1.221486\n",
      "Train Epoch: 9 [25600/60000 ( 43%)]  Loss: 0.985804\n",
      "Train Epoch: 9 [38400/60000 ( 64%)]  Loss: 0.899610\n",
      "Train Epoch: 9 [51200/60000 ( 85%)]  Loss: 0.907500\n",
      "Test set: Average loss: 0.0075, Accuracy: 40202/60000 (67.00%)\n",
      "Test set: Average loss: 0.0088, Accuracy: 6937/10000 (69.37%)\n",
      "Train Epoch: 10 [    0/60000 (  0%)]  Loss: 0.933930\n",
      "Train Epoch: 10 [12800/60000 ( 21%)]  Loss: 1.006101\n",
      "Train Epoch: 10 [25600/60000 ( 43%)]  Loss: 0.973285\n",
      "Train Epoch: 10 [38400/60000 ( 64%)]  Loss: 1.012568\n",
      "Train Epoch: 10 [51200/60000 ( 85%)]  Loss: 1.030444\n",
      "Test set: Average loss: 0.0075, Accuracy: 40128/60000 (66.88%)\n",
      "Test set: Average loss: 0.0083, Accuracy: 7125/10000 (71.25%)\n",
      "Train Epoch: 11 [    0/60000 (  0%)]  Loss: 1.019686\n",
      "Train Epoch: 11 [12800/60000 ( 21%)]  Loss: 1.185019\n",
      "Train Epoch: 11 [25600/60000 ( 43%)]  Loss: 0.838640\n",
      "Train Epoch: 11 [38400/60000 ( 64%)]  Loss: 0.963232\n",
      "Train Epoch: 11 [51200/60000 ( 85%)]  Loss: 0.857085\n",
      "Test set: Average loss: 0.0073, Accuracy: 40458/60000 (67.43%)\n",
      "Test set: Average loss: 0.0091, Accuracy: 6678/10000 (66.78%)\n",
      "Train Epoch: 12 [    0/60000 (  0%)]  Loss: 1.024933\n",
      "Train Epoch: 12 [12800/60000 ( 21%)]  Loss: 0.927273\n",
      "Train Epoch: 12 [25600/60000 ( 43%)]  Loss: 0.831933\n",
      "Train Epoch: 12 [38400/60000 ( 64%)]  Loss: 0.955251\n",
      "Train Epoch: 12 [51200/60000 ( 85%)]  Loss: 1.005221\n",
      "Test set: Average loss: 0.0074, Accuracy: 40350/60000 (67.25%)\n",
      "Test set: Average loss: 0.0083, Accuracy: 6969/10000 (69.69%)\n",
      "Train Epoch: 13 [    0/60000 (  0%)]  Loss: 0.928212\n",
      "Train Epoch: 13 [12800/60000 ( 21%)]  Loss: 0.835803\n",
      "Train Epoch: 13 [25600/60000 ( 43%)]  Loss: 1.099943\n",
      "Train Epoch: 13 [38400/60000 ( 64%)]  Loss: 1.111604\n",
      "Train Epoch: 13 [51200/60000 ( 85%)]  Loss: 1.112520\n",
      "Test set: Average loss: 0.0072, Accuracy: 40683/60000 (67.81%)\n",
      "Test set: Average loss: 0.0090, Accuracy: 6696/10000 (66.96%)\n",
      "Train Epoch: 14 [    0/60000 (  0%)]  Loss: 1.005040\n",
      "Train Epoch: 14 [12800/60000 ( 21%)]  Loss: 0.920245\n",
      "Train Epoch: 14 [25600/60000 ( 43%)]  Loss: 0.788351\n",
      "Train Epoch: 14 [38400/60000 ( 64%)]  Loss: 0.903132\n",
      "Train Epoch: 14 [51200/60000 ( 85%)]  Loss: 0.944763\n",
      "Test set: Average loss: 0.0071, Accuracy: 41295/60000 (68.83%)\n",
      "Test set: Average loss: 0.0090, Accuracy: 6793/10000 (67.93%)\n",
      "Train Epoch: 15 [    0/60000 (  0%)]  Loss: 0.830660\n",
      "Train Epoch: 15 [12800/60000 ( 21%)]  Loss: 0.961572\n",
      "Train Epoch: 15 [25600/60000 ( 43%)]  Loss: 0.873854\n",
      "Train Epoch: 15 [38400/60000 ( 64%)]  Loss: 0.915213\n",
      "Train Epoch: 15 [51200/60000 ( 85%)]  Loss: 0.872457\n",
      "Test set: Average loss: 0.0071, Accuracy: 41153/60000 (68.59%)\n",
      "Test set: Average loss: 0.0089, Accuracy: 6837/10000 (68.37%)\n",
      "Train Epoch: 16 [    0/60000 (  0%)]  Loss: 0.764852\n",
      "Train Epoch: 16 [12800/60000 ( 21%)]  Loss: 0.917633\n",
      "Train Epoch: 16 [25600/60000 ( 43%)]  Loss: 0.950755\n",
      "Train Epoch: 16 [38400/60000 ( 64%)]  Loss: 0.835173\n",
      "Train Epoch: 16 [51200/60000 ( 85%)]  Loss: 0.881759\n",
      "Test set: Average loss: 0.0070, Accuracy: 41317/60000 (68.86%)\n",
      "Test set: Average loss: 0.0082, Accuracy: 7131/10000 (71.31%)\n",
      "Train Epoch: 17 [    0/60000 (  0%)]  Loss: 0.849506\n",
      "Train Epoch: 17 [12800/60000 ( 21%)]  Loss: 0.878673\n",
      "Train Epoch: 17 [25600/60000 ( 43%)]  Loss: 0.959876\n",
      "Train Epoch: 17 [38400/60000 ( 64%)]  Loss: 0.921284\n",
      "Train Epoch: 17 [51200/60000 ( 85%)]  Loss: 0.864335\n",
      "Test set: Average loss: 0.0067, Accuracy: 42146/60000 (70.24%)\n",
      "Test set: Average loss: 0.0081, Accuracy: 7064/10000 (70.64%)\n",
      "Train Epoch: 18 [    0/60000 (  0%)]  Loss: 0.851822\n",
      "Train Epoch: 18 [12800/60000 ( 21%)]  Loss: 0.993170\n",
      "Train Epoch: 18 [25600/60000 ( 43%)]  Loss: 0.911865\n",
      "Train Epoch: 18 [38400/60000 ( 64%)]  Loss: 0.830094\n",
      "Train Epoch: 18 [51200/60000 ( 85%)]  Loss: 0.928912\n",
      "Test set: Average loss: 0.0068, Accuracy: 41886/60000 (69.81%)\n",
      "Test set: Average loss: 0.0084, Accuracy: 6949/10000 (69.49%)\n",
      "Train Epoch: 19 [    0/60000 (  0%)]  Loss: 0.751157\n",
      "Train Epoch: 19 [12800/60000 ( 21%)]  Loss: 0.831823\n",
      "Train Epoch: 19 [25600/60000 ( 43%)]  Loss: 1.079046\n",
      "Train Epoch: 19 [38400/60000 ( 64%)]  Loss: 0.761960\n",
      "Train Epoch: 19 [51200/60000 ( 85%)]  Loss: 0.864894\n",
      "Test set: Average loss: 0.0067, Accuracy: 42304/60000 (70.51%)\n",
      "Test set: Average loss: 0.0081, Accuracy: 7074/10000 (70.74%)\n",
      "Train Epoch: 20 [    0/60000 (  0%)]  Loss: 0.805853\n",
      "Train Epoch: 20 [12800/60000 ( 21%)]  Loss: 1.039262\n",
      "Train Epoch: 20 [25600/60000 ( 43%)]  Loss: 0.821017\n",
      "Train Epoch: 20 [38400/60000 ( 64%)]  Loss: 0.782925\n",
      "Train Epoch: 20 [51200/60000 ( 85%)]  Loss: 1.025789\n",
      "Test set: Average loss: 0.0067, Accuracy: 42187/60000 (70.31%)\n",
      "Test set: Average loss: 0.0078, Accuracy: 7288/10000 (72.88%)\n",
      "Train Epoch: 21 [    0/60000 (  0%)]  Loss: 0.973513\n",
      "Train Epoch: 21 [12800/60000 ( 21%)]  Loss: 0.877645\n",
      "Train Epoch: 21 [25600/60000 ( 43%)]  Loss: 0.980955\n",
      "Train Epoch: 21 [38400/60000 ( 64%)]  Loss: 0.807789\n",
      "Train Epoch: 21 [51200/60000 ( 85%)]  Loss: 0.694978\n",
      "Test set: Average loss: 0.0065, Accuracy: 42546/60000 (70.91%)\n",
      "Test set: Average loss: 0.0080, Accuracy: 7111/10000 (71.11%)\n",
      "Train Epoch: 22 [    0/60000 (  0%)]  Loss: 0.818053\n",
      "Train Epoch: 22 [12800/60000 ( 21%)]  Loss: 0.853306\n",
      "Train Epoch: 22 [25600/60000 ( 43%)]  Loss: 0.924111\n",
      "Train Epoch: 22 [38400/60000 ( 64%)]  Loss: 0.892516\n",
      "Train Epoch: 22 [51200/60000 ( 85%)]  Loss: 0.915633\n",
      "Test set: Average loss: 0.0065, Accuracy: 42667/60000 (71.11%)\n",
      "Test set: Average loss: 0.0075, Accuracy: 7407/10000 (74.07%)\n",
      "Train Epoch: 23 [    0/60000 (  0%)]  Loss: 0.873584\n",
      "Train Epoch: 23 [12800/60000 ( 21%)]  Loss: 1.059685\n",
      "Train Epoch: 23 [25600/60000 ( 43%)]  Loss: 0.700236\n",
      "Train Epoch: 23 [38400/60000 ( 64%)]  Loss: 0.812766\n",
      "Train Epoch: 23 [51200/60000 ( 85%)]  Loss: 0.861644\n",
      "Test set: Average loss: 0.0065, Accuracy: 42434/60000 (70.72%)\n",
      "Test set: Average loss: 0.0078, Accuracy: 7273/10000 (72.73%)\n",
      "Train Epoch: 24 [    0/60000 (  0%)]  Loss: 0.939352\n",
      "Train Epoch: 24 [12800/60000 ( 21%)]  Loss: 1.020412\n",
      "Train Epoch: 24 [25600/60000 ( 43%)]  Loss: 0.825087\n",
      "Train Epoch: 24 [38400/60000 ( 64%)]  Loss: 0.676315\n",
      "Train Epoch: 24 [51200/60000 ( 85%)]  Loss: 0.764476\n",
      "Test set: Average loss: 0.0064, Accuracy: 42995/60000 (71.66%)\n",
      "Test set: Average loss: 0.0077, Accuracy: 7261/10000 (72.61%)\n",
      "Train Epoch: 25 [    0/60000 (  0%)]  Loss: 0.842636\n",
      "Train Epoch: 25 [12800/60000 ( 21%)]  Loss: 0.976342\n",
      "Train Epoch: 25 [25600/60000 ( 43%)]  Loss: 0.909494\n",
      "Train Epoch: 25 [38400/60000 ( 64%)]  Loss: 0.798675\n",
      "Train Epoch: 25 [51200/60000 ( 85%)]  Loss: 0.920512\n",
      "Test set: Average loss: 0.0064, Accuracy: 42924/60000 (71.54%)\n",
      "Test set: Average loss: 0.0082, Accuracy: 7060/10000 (70.60%)\n",
      "Train Epoch: 26 [    0/60000 (  0%)]  Loss: 0.869404\n",
      "Train Epoch: 26 [12800/60000 ( 21%)]  Loss: 0.827692\n",
      "Train Epoch: 26 [25600/60000 ( 43%)]  Loss: 0.789185\n",
      "Train Epoch: 26 [38400/60000 ( 64%)]  Loss: 0.741398\n",
      "Train Epoch: 26 [51200/60000 ( 85%)]  Loss: 0.815519\n",
      "Test set: Average loss: 0.0065, Accuracy: 42775/60000 (71.29%)\n",
      "Test set: Average loss: 0.0077, Accuracy: 7321/10000 (73.21%)\n",
      "Train Epoch: 27 [    0/60000 (  0%)]  Loss: 0.847715\n",
      "Train Epoch: 27 [12800/60000 ( 21%)]  Loss: 0.905396\n",
      "Train Epoch: 27 [25600/60000 ( 43%)]  Loss: 0.745716\n",
      "Train Epoch: 27 [38400/60000 ( 64%)]  Loss: 0.766024\n",
      "Train Epoch: 27 [51200/60000 ( 85%)]  Loss: 0.741846\n",
      "Test set: Average loss: 0.0063, Accuracy: 43311/60000 (72.19%)\n",
      "Test set: Average loss: 0.0075, Accuracy: 7255/10000 (72.55%)\n",
      "Train Epoch: 28 [    0/60000 (  0%)]  Loss: 0.720773\n",
      "Train Epoch: 28 [12800/60000 ( 21%)]  Loss: 0.748312\n",
      "Train Epoch: 28 [25600/60000 ( 43%)]  Loss: 0.725667\n",
      "Train Epoch: 28 [38400/60000 ( 64%)]  Loss: 0.750858\n",
      "Train Epoch: 28 [51200/60000 ( 85%)]  Loss: 0.971334\n",
      "Test set: Average loss: 0.0063, Accuracy: 43146/60000 (71.91%)\n",
      "Test set: Average loss: 0.0070, Accuracy: 7613/10000 (76.13%)\n",
      "Train Epoch: 29 [    0/60000 (  0%)]  Loss: 0.963905\n",
      "Train Epoch: 29 [12800/60000 ( 21%)]  Loss: 0.854922\n",
      "Train Epoch: 29 [25600/60000 ( 43%)]  Loss: 0.856583\n",
      "Train Epoch: 29 [38400/60000 ( 64%)]  Loss: 0.816660\n",
      "Train Epoch: 29 [51200/60000 ( 85%)]  Loss: 1.013172\n",
      "Test set: Average loss: 0.0063, Accuracy: 43155/60000 (71.92%)\n",
      "Test set: Average loss: 0.0076, Accuracy: 7300/10000 (73.00%)\n",
      "Train Epoch: 30 [    0/60000 (  0%)]  Loss: 0.794853\n",
      "Train Epoch: 30 [12800/60000 ( 21%)]  Loss: 0.812287\n",
      "Train Epoch: 30 [25600/60000 ( 43%)]  Loss: 0.748554\n",
      "Train Epoch: 30 [38400/60000 ( 64%)]  Loss: 0.674344\n",
      "Train Epoch: 30 [51200/60000 ( 85%)]  Loss: 0.778591\n",
      "Test set: Average loss: 0.0061, Accuracy: 43520/60000 (72.53%)\n",
      "Test set: Average loss: 0.0072, Accuracy: 7459/10000 (74.59%)\n",
      "Train Epoch: 31 [    0/60000 (  0%)]  Loss: 0.749098\n",
      "Train Epoch: 31 [12800/60000 ( 21%)]  Loss: 0.832417\n",
      "Train Epoch: 31 [25600/60000 ( 43%)]  Loss: 0.851015\n",
      "Train Epoch: 31 [38400/60000 ( 64%)]  Loss: 0.947201\n",
      "Train Epoch: 31 [51200/60000 ( 85%)]  Loss: 0.650105\n",
      "Test set: Average loss: 0.0062, Accuracy: 43618/60000 (72.70%)\n",
      "Test set: Average loss: 0.0070, Accuracy: 7556/10000 (75.56%)\n",
      "Train Epoch: 32 [    0/60000 (  0%)]  Loss: 0.797945\n",
      "Train Epoch: 32 [12800/60000 ( 21%)]  Loss: 1.007569\n",
      "Train Epoch: 32 [25600/60000 ( 43%)]  Loss: 0.709899\n",
      "Train Epoch: 32 [38400/60000 ( 64%)]  Loss: 0.759834\n",
      "Train Epoch: 32 [51200/60000 ( 85%)]  Loss: 0.565483\n",
      "Test set: Average loss: 0.0061, Accuracy: 43643/60000 (72.74%)\n",
      "Test set: Average loss: 0.0070, Accuracy: 7616/10000 (76.16%)\n",
      "Train Epoch: 33 [    0/60000 (  0%)]  Loss: 0.707999\n",
      "Train Epoch: 33 [12800/60000 ( 21%)]  Loss: 0.718512\n",
      "Train Epoch: 33 [25600/60000 ( 43%)]  Loss: 0.732418\n",
      "Train Epoch: 33 [38400/60000 ( 64%)]  Loss: 0.835429\n",
      "Train Epoch: 33 [51200/60000 ( 85%)]  Loss: 0.647138\n",
      "Test set: Average loss: 0.0061, Accuracy: 43762/60000 (72.94%)\n",
      "Test set: Average loss: 0.0071, Accuracy: 7488/10000 (74.88%)\n",
      "Train Epoch: 34 [    0/60000 (  0%)]  Loss: 0.785302\n",
      "Train Epoch: 34 [12800/60000 ( 21%)]  Loss: 0.896146\n",
      "Train Epoch: 34 [25600/60000 ( 43%)]  Loss: 0.783222\n",
      "Train Epoch: 34 [38400/60000 ( 64%)]  Loss: 0.669563\n",
      "Train Epoch: 34 [51200/60000 ( 85%)]  Loss: 0.811274\n",
      "Test set: Average loss: 0.0061, Accuracy: 43571/60000 (72.62%)\n",
      "Test set: Average loss: 0.0072, Accuracy: 7412/10000 (74.12%)\n",
      "Train Epoch: 35 [    0/60000 (  0%)]  Loss: 0.747313\n",
      "Train Epoch: 35 [12800/60000 ( 21%)]  Loss: 0.790216\n",
      "Train Epoch: 35 [25600/60000 ( 43%)]  Loss: 0.692285\n",
      "Train Epoch: 35 [38400/60000 ( 64%)]  Loss: 0.816588\n",
      "Train Epoch: 35 [51200/60000 ( 85%)]  Loss: 0.786051\n",
      "Test set: Average loss: 0.0061, Accuracy: 43854/60000 (73.09%)\n",
      "Test set: Average loss: 0.0072, Accuracy: 7436/10000 (74.36%)\n",
      "Train Epoch: 36 [    0/60000 (  0%)]  Loss: 0.998835\n",
      "Train Epoch: 36 [12800/60000 ( 21%)]  Loss: 0.678300\n",
      "Train Epoch: 36 [25600/60000 ( 43%)]  Loss: 0.890034\n",
      "Train Epoch: 36 [38400/60000 ( 64%)]  Loss: 0.714628\n",
      "Train Epoch: 36 [51200/60000 ( 85%)]  Loss: 0.702258\n",
      "Test set: Average loss: 0.0060, Accuracy: 43866/60000 (73.11%)\n",
      "Test set: Average loss: 0.0073, Accuracy: 7421/10000 (74.21%)\n",
      "Train Epoch: 37 [    0/60000 (  0%)]  Loss: 0.575967\n",
      "Train Epoch: 37 [12800/60000 ( 21%)]  Loss: 0.914183\n",
      "Train Epoch: 37 [25600/60000 ( 43%)]  Loss: 0.758163\n",
      "Train Epoch: 37 [38400/60000 ( 64%)]  Loss: 0.785919\n",
      "Train Epoch: 37 [51200/60000 ( 85%)]  Loss: 0.718168\n",
      "Test set: Average loss: 0.0061, Accuracy: 43752/60000 (72.92%)\n",
      "Test set: Average loss: 0.0076, Accuracy: 7336/10000 (73.36%)\n",
      "Train Epoch: 38 [    0/60000 (  0%)]  Loss: 0.881765\n",
      "Train Epoch: 38 [12800/60000 ( 21%)]  Loss: 0.679019\n",
      "Train Epoch: 38 [25600/60000 ( 43%)]  Loss: 0.851945\n",
      "Train Epoch: 38 [38400/60000 ( 64%)]  Loss: 0.647841\n",
      "Train Epoch: 38 [51200/60000 ( 85%)]  Loss: 0.753255\n",
      "Test set: Average loss: 0.0060, Accuracy: 44155/60000 (73.59%)\n",
      "Test set: Average loss: 0.0072, Accuracy: 7491/10000 (74.91%)\n",
      "Train Epoch: 39 [    0/60000 (  0%)]  Loss: 0.884626\n",
      "Train Epoch: 39 [12800/60000 ( 21%)]  Loss: 0.730737\n",
      "Train Epoch: 39 [25600/60000 ( 43%)]  Loss: 0.820108\n",
      "Train Epoch: 39 [38400/60000 ( 64%)]  Loss: 0.681593\n",
      "Train Epoch: 39 [51200/60000 ( 85%)]  Loss: 0.570633\n",
      "Test set: Average loss: 0.0060, Accuracy: 44175/60000 (73.62%)\n",
      "Test set: Average loss: 0.0071, Accuracy: 7410/10000 (74.10%)\n",
      "Train Epoch: 40 [    0/60000 (  0%)]  Loss: 0.881517\n",
      "Train Epoch: 40 [12800/60000 ( 21%)]  Loss: 0.711669\n",
      "Train Epoch: 40 [25600/60000 ( 43%)]  Loss: 0.784387\n",
      "Train Epoch: 40 [38400/60000 ( 64%)]  Loss: 0.783641\n",
      "Train Epoch: 40 [51200/60000 ( 85%)]  Loss: 0.615968\n",
      "Test set: Average loss: 0.0060, Accuracy: 44036/60000 (73.39%)\n",
      "Test set: Average loss: 0.0072, Accuracy: 7453/10000 (74.53%)\n",
      "Train Epoch: 41 [    0/60000 (  0%)]  Loss: 0.847182\n",
      "Train Epoch: 41 [12800/60000 ( 21%)]  Loss: 0.813366\n",
      "Train Epoch: 41 [25600/60000 ( 43%)]  Loss: 0.764818\n",
      "Train Epoch: 41 [38400/60000 ( 64%)]  Loss: 0.749932\n",
      "Train Epoch: 41 [51200/60000 ( 85%)]  Loss: 0.712926\n",
      "Test set: Average loss: 0.0060, Accuracy: 43844/60000 (73.07%)\n",
      "Test set: Average loss: 0.0074, Accuracy: 7427/10000 (74.27%)\n",
      "Train Epoch: 42 [    0/60000 (  0%)]  Loss: 0.821537\n",
      "Train Epoch: 42 [12800/60000 ( 21%)]  Loss: 0.794411\n",
      "Train Epoch: 42 [25600/60000 ( 43%)]  Loss: 0.896761\n",
      "Train Epoch: 42 [38400/60000 ( 64%)]  Loss: 0.771536\n",
      "Train Epoch: 42 [51200/60000 ( 85%)]  Loss: 0.904350\n",
      "Test set: Average loss: 0.0059, Accuracy: 44200/60000 (73.67%)\n",
      "Test set: Average loss: 0.0067, Accuracy: 7698/10000 (76.98%)\n",
      "Train Epoch: 43 [    0/60000 (  0%)]  Loss: 0.788927\n",
      "Train Epoch: 43 [12800/60000 ( 21%)]  Loss: 0.644491\n",
      "Train Epoch: 43 [25600/60000 ( 43%)]  Loss: 0.694739\n",
      "Train Epoch: 43 [38400/60000 ( 64%)]  Loss: 0.593577\n",
      "Train Epoch: 43 [51200/60000 ( 85%)]  Loss: 0.746632\n",
      "Test set: Average loss: 0.0058, Accuracy: 44562/60000 (74.27%)\n",
      "Test set: Average loss: 0.0070, Accuracy: 7542/10000 (75.42%)\n",
      "Train Epoch: 44 [    0/60000 (  0%)]  Loss: 0.742829\n",
      "Train Epoch: 44 [12800/60000 ( 21%)]  Loss: 0.779885\n",
      "Train Epoch: 44 [25600/60000 ( 43%)]  Loss: 0.784192\n",
      "Train Epoch: 44 [38400/60000 ( 64%)]  Loss: 0.630037\n",
      "Train Epoch: 44 [51200/60000 ( 85%)]  Loss: 0.809684\n",
      "Test set: Average loss: 0.0059, Accuracy: 44285/60000 (73.81%)\n",
      "Test set: Average loss: 0.0068, Accuracy: 7604/10000 (76.04%)\n",
      "Train Epoch: 45 [    0/60000 (  0%)]  Loss: 0.650329\n",
      "Train Epoch: 45 [12800/60000 ( 21%)]  Loss: 0.708310\n",
      "Train Epoch: 45 [25600/60000 ( 43%)]  Loss: 1.033067\n",
      "Train Epoch: 45 [38400/60000 ( 64%)]  Loss: 0.750096\n",
      "Train Epoch: 45 [51200/60000 ( 85%)]  Loss: 0.787990\n",
      "Test set: Average loss: 0.0058, Accuracy: 44440/60000 (74.07%)\n",
      "Test set: Average loss: 0.0070, Accuracy: 7564/10000 (75.64%)\n",
      "Train Epoch: 46 [    0/60000 (  0%)]  Loss: 0.617703\n",
      "Train Epoch: 46 [12800/60000 ( 21%)]  Loss: 0.826153\n",
      "Train Epoch: 46 [25600/60000 ( 43%)]  Loss: 0.952991\n",
      "Train Epoch: 46 [38400/60000 ( 64%)]  Loss: 0.738006\n",
      "Train Epoch: 46 [51200/60000 ( 85%)]  Loss: 0.840806\n",
      "Test set: Average loss: 0.0058, Accuracy: 44486/60000 (74.14%)\n",
      "Test set: Average loss: 0.0068, Accuracy: 7685/10000 (76.85%)\n",
      "Train Epoch: 47 [    0/60000 (  0%)]  Loss: 0.666653\n",
      "Train Epoch: 47 [12800/60000 ( 21%)]  Loss: 0.797558\n",
      "Train Epoch: 47 [25600/60000 ( 43%)]  Loss: 0.667048\n",
      "Train Epoch: 47 [38400/60000 ( 64%)]  Loss: 0.704358\n",
      "Train Epoch: 47 [51200/60000 ( 85%)]  Loss: 0.726696\n",
      "Test set: Average loss: 0.0057, Accuracy: 44606/60000 (74.34%)\n",
      "Test set: Average loss: 0.0074, Accuracy: 7324/10000 (73.24%)\n",
      "Train Epoch: 48 [    0/60000 (  0%)]  Loss: 0.800047\n",
      "Train Epoch: 48 [12800/60000 ( 21%)]  Loss: 0.651788\n",
      "Train Epoch: 48 [25600/60000 ( 43%)]  Loss: 0.742545\n",
      "Train Epoch: 48 [38400/60000 ( 64%)]  Loss: 0.726981\n",
      "Train Epoch: 48 [51200/60000 ( 85%)]  Loss: 0.625497\n",
      "Test set: Average loss: 0.0059, Accuracy: 44426/60000 (74.04%)\n",
      "Test set: Average loss: 0.0067, Accuracy: 7627/10000 (76.27%)\n",
      "Train Epoch: 49 [    0/60000 (  0%)]  Loss: 0.805300\n",
      "Train Epoch: 49 [12800/60000 ( 21%)]  Loss: 0.834029\n",
      "Train Epoch: 49 [25600/60000 ( 43%)]  Loss: 0.746426\n",
      "Train Epoch: 49 [38400/60000 ( 64%)]  Loss: 0.632337\n",
      "Train Epoch: 49 [51200/60000 ( 85%)]  Loss: 0.727297\n",
      "Test set: Average loss: 0.0057, Accuracy: 44707/60000 (74.51%)\n",
      "Test set: Average loss: 0.0073, Accuracy: 7452/10000 (74.52%)\n",
      "Test set: Average loss: 0.0058, Accuracy: 44620/60000 (74.37%)\n",
      "Test set: Average loss: 0.0073, Accuracy: 7452/10000 (74.52%)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.52"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train(50)\n",
    "test(trainloader)\n",
    "test(testloader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_by_row(logits, T = 1.0):\n",
    "    mx = np.max(logits, axis=-1, keepdims=True)\n",
    "    exp = np.exp((logits - mx)/T)\n",
    "    denominator = np.sum(exp, axis=-1, keepdims=True)\n",
    "    return exp/denominator\n",
    "\n",
    "def classifier_performance(model, train_loader, test_loader):\n",
    "\n",
    "    output_train_benign = []\n",
    "    train_label = []\n",
    "    for num, data in enumerate(train_loader):\n",
    "        images,labels = data\n",
    "        image_tensor= images.to(device)\n",
    "        img_variable = Variable(image_tensor, requires_grad=True)\n",
    "        output = model.forward(img_variable)\n",
    "\n",
    "        train_label.append(labels.numpy())\n",
    "        logits = output.logits\n",
    "        output_train_benign.append(softmax_by_row(logits.cpu().detach().numpy(),T = 1))\n",
    "\n",
    "\n",
    "    train_label = np.concatenate(train_label)\n",
    "    output_train_benign=np.concatenate(output_train_benign)\n",
    "\n",
    "    test_label = []\n",
    "    output_test_benign = []\n",
    "\n",
    "    for num, data in enumerate(test_loader):\n",
    "        images,labels = data\n",
    "\n",
    "        image_tensor= images.to(device)\n",
    "        img_variable = Variable(image_tensor, requires_grad=True)\n",
    "\n",
    "        output = model.forward(img_variable)\n",
    "\n",
    "        test_label.append(labels.numpy())\n",
    "        logits = output.logits\n",
    "        output_test_benign.append(softmax_by_row(logits.cpu().detach().numpy(),T = 1))\n",
    "\n",
    "\n",
    "    test_label = np.concatenate(test_label)\n",
    "    output_test_benign=np.concatenate(output_test_benign)\n",
    "\n",
    "\n",
    "    train_acc1 = np.sum(np.argmax(output_train_benign,axis=1) == train_label.flatten())/len(train_label)\n",
    "    test_acc1 = np.sum(np.argmax(output_test_benign,axis=1) == test_label.flatten())/len(test_label)\n",
    "\n",
    "    print('Accuracy: ', (train_acc1, test_acc1))\n",
    "\n",
    "    return output_train_benign, output_test_benign, train_label, test_label\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def inference_via_confidence(confidence_mtx1, confidence_mtx2, label_vec1, label_vec2):\n",
    "    \n",
    "    #----------------First step: obtain confidence lists for both training dataset and test dataset--------------\n",
    "    confidence1 = []\n",
    "    confidence2 = []\n",
    "    acc1 = 0\n",
    "    acc2 = 0\n",
    "    for num in range(confidence_mtx1.shape[0]):\n",
    "        confidence1.append(confidence_mtx1[num,label_vec1[num]])\n",
    "        if np.argmax(confidence_mtx1[num,:]) == label_vec1[num]:\n",
    "            acc1 += 1\n",
    "            \n",
    "    for num in range(confidence_mtx2.shape[0]):\n",
    "        confidence2.append(confidence_mtx2[num,label_vec2[num]])\n",
    "        if np.argmax(confidence_mtx2[num,:]) == label_vec2[num]:\n",
    "            acc2 += 1\n",
    "    confidence1 = np.array(confidence1)\n",
    "    confidence2 = np.array(confidence2)\n",
    "    \n",
    "    print('model accuracy for training and test-', (acc1/confidence_mtx1.shape[0], acc2/confidence_mtx2.shape[0]) )\n",
    "    \n",
    "    \n",
    "    #sort_confidence = np.sort(confidence1)\n",
    "    sort_confidence = np.sort(np.concatenate((confidence1, confidence2)))\n",
    "    max_accuracy = 0.5\n",
    "    best_precision = 0.5\n",
    "    best_recall = 0.5\n",
    "    for num in range(len(sort_confidence)):\n",
    "        delta = sort_confidence[num]\n",
    "        ratio1 = np.sum(confidence1>=delta)/confidence_mtx1.shape[0]\n",
    "        ratio2 = np.sum(confidence2>=delta)/confidence_mtx2.shape[0]\n",
    "        accuracy_now = 0.5*(ratio1+1-ratio2)\n",
    "        if accuracy_now > max_accuracy:\n",
    "            max_accuracy = accuracy_now\n",
    "            best_precision = ratio1/(ratio1+ratio2)\n",
    "            best_recall = ratio1\n",
    "    print('membership inference accuracy is:', max_accuracy)\n",
    "    return max_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  (0.74015, 0.7452)\n",
      "model accuracy for training and test- (0.74015, 0.7452)\n",
      "membership inference accuracy is: 0.5439416666666667\n",
      "Maximum Accuracy: 0.5439416666666667\n"
     ]
    }
   ],
   "source": [
    "from torch.autograd import Variable\n",
    "import os\n",
    "import numpy as np\n",
    "import math \n",
    "import scipy\n",
    "import sys  \n",
    "\n",
    "output_train, output_test, train_label, test_label = classifier_performance(model, trainloader, testloader)\n",
    "inference_accuracy=inference_via_confidence(output_train, output_test, train_label, test_label)\n",
    "print(\"Maximum Accuracy:\",inference_accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
